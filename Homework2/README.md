**Описание Homework2:**

Блок 1. Standalone Spark.
1) Развернуть standalone cluster Spark: master + 2 workers. Приложить скрипт и/или алгоритм + скрин webui (10 баллов);
2) Подключиться к кластеру с помощью Jupyter и/или Zeppelin. Приложить скрипт и/или алгоритм + скрин рабочей сессии из инструмента (20 баллов).

Блок 2. Работа с данными на Spark.
1) Преобразовать данные исходного датасета в parquet объединяя все таблицы. Оценить разницу в скорости чтения / занимаемом объеме. Сделать выводы. (15 баллов);
2) Используя весь набор данных с помощью Spark вывести (5 баллов за каждое задание):
    - Топ-10 книг с наибольшим числом ревью;
    - Топ-10 издателей с наибольшим средним числом страниц в книгах;
    - Десять наиболее активных по числу изданных книг лет;
    - Топ-10 книг имеющих наибольший разброс в оценках среди книг имеющих больше 500 оценок;
    - Любой интересный инсайт из данных.
  
Блок 3. Spark Streaming.

В задании предлагается реализовать расчет среднего рейтинга книги на Spark Streaming со следующими условиями (30 баллов):
- использовать данные user_rating как file source;
- использовать file sink в формате parquet.
