**Описание Homework1:**

Блок 1. Развертывание локального кластера Hadoop.
1) Развернуть локальный кластер в конфигурации 1 NN, 2 DN + 2 NM, 1 RM, 1 History server (опционально);
2) Изучить настройки и состояние NM и RM в веб-интерфейсе;
3) Сделать скриншоты NN и RM, добавить в репозиторий.

Блок 2. Написание map reduce на Python.
В данной задаче мы будем подсчитывать среднее значение (аналог- numpy.mean) и дисперсию (аналог numpy.var) для сета из N сплитов данных с помощью map-reduce парадигмы.
1) Маппер функция должна генерить k кортежей вида (сk, mk, vk), где ck-размер chunk_size, mk-среднее данного chunk и vk - его дисперсия;
2) Редюсер функция должна скомбинировать полученные кортежи, вычислить результаты среднего значения и дисперсии величины и записать их в выходной файл.
За правильное исполнение map-reduce части для подсчета среднего значения начисляется 25 баллов и также 25 баллов можно получить за map-reduce подсчета дисперсии указанной величины.

**Описание файлов в папке:**

* Scree_Nodes.png, Screen_about_the_cluster.png - скриншоты NN и RM в веб-интерфейсе;
* commands.txt - команда для запуска mapreduce;
* part-00000 - результат работы mapreduce;
* mapper.py, reducer.py - скрипты одновременно для среднего и дисперсии;
* results.txt - результаты сравнения подсчетов двумя разными способами среднего и дисперсии.
